{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([3,3,2], dtype = None, device='cuda', requires_grad=False)\n",
    "vector.type(torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the max, mean, min, etc of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,11, 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10), tensor(0), tensor(10), tensor(0))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get max and min\n",
    "x.max(), x.min(), torch.max(x), torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(5.), tensor(55), tensor(55))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .mean() method can only take in float or complex dtype, so we have to convert it\n",
    "x.type(torch.float32).mean(), torch.mean(x.type(torch.float32)), x.sum(), torch.sum(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(10), tensor(0), tensor(10))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index at which the max/ min occurs at\n",
    "x.argmin(), x.argmax(), torch.argmin(x), torch.argmax(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, viewing, stacking, squeezing, and unsqueezing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the dimensions. Would work with any combination as long as the size stays the same\n",
    "x_reshaped = x.reshape(1,10)\n",
    "x_reshaped = x.reshape(10,1)\n",
    "# x_reshaped = x.reshape(5,2)\n",
    "# x_reshaped = x.reshape(2,5)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.],\n",
       "         [ 5.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(2,5)\n",
    "z, z.shape\n",
    "\n",
    "# Changing z changes x (because a view of a tensor shares the same memeory as the original tensor)\n",
    "z[:,0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x], dim = 0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 5.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]]),\n",
       " torch.Size([10, 1]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes all single dimensions from a tensor\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.squeeze(), x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.])\n",
      "Previous shape: torch.Size([10])\n",
      "\n",
      "New target: tensor([[ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.]])\n",
      "New shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze - adds a single dimension to a target tensor at a specific dim\n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dim\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim = 0)\n",
    "print(f\"\\nNew target: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Permute - returns a view with elements rearranged\n",
    "x_original = torch.rand(size = (224, 224, 3)) # [height, width, colour_channels] -> image data\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order, i.e. (height, width, colour_channels) -> (colour_channels, height, width)\n",
    "# !! Permuted tensors shares same memory with original tensors \n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "x_permuted.shape\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensors & NumPy\n",
    "* Data in NumPy, want in PyTorch tensor\n",
    "* PyTorch tensor -> NumpPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.]),\n",
       " dtype('float64'),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !! Numpy default is float64, but pytorch tensor default is float32\n",
    "array = np.arange(1.0,8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor, array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing value in array doesn't change in tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " torch.float32,\n",
       " dtype('float32'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor, tensor.dtype, numpy_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing value in tensor doesn't change in array\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27ee4d5ff70>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility, set seed\n",
    "RANDOM_NUMBER = 42\n",
    "torch.manual_seed(RANDOM_NUMBER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practice to setup device agnostic code\n",
    "\n",
    "e.g. run on GPU if available, otherwise run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 2, 3]), tensor([1, 2, 3], device='cuda:0'))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0] = 6\n",
    "# Changing tensor doesn't affect tensor_on_gpu, they do not share the same memory\n",
    "tensor, tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy\n",
    "# tensor_on_gpu.numpy()\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41bb379b8c51879f8791d8a58ee2c268e30c191141e9580158e121a673ab260e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
